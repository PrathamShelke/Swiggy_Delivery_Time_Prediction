
Steps
1)Performed Basic Data Exploration and Cleaned the Data
2)Using Data Cleaning Code in the notebook 01 created data_clean_utils.py file and created swiggy_cleaned.csv
3)Performed EDA in 02 notebook to understand data properly by performing univariate,bivariate and multivariate analysis.

4)Building Baseline Model(Linear Regression,RandomForest) in 03 notebook using 2 ways without Missing Val(NAN) and Imputation of missing vals
Evaluating both the Baseline model with metrics like MAE,R2 Score.

Through this Process of Baseline Model we found out that RandomForest is Good Baseline Model.

5)We performed below experiments with help of Dagshub(Github for ML) and MLFlow(Experiment tracking).

Performed EXP1: Where we will use RandomForest in 2 ways without Missing Values and Imputation of Missing Vals.

Performed EXP2:Where we use RandomForest with Imputation and adding Missing Indicator

Performed EXP3:Where we did model selection and found RandomForest and LightGBM as good models

Performed EXP4 and EXP5: We performed hyperparameter tuning on this 2 models to find best params through optuna.

Performed EXP6: Using RF,LightGBM as base learners we built stacking regressor and found best meta estimator model as Linear Regression.

Performed EXP7:We logged the best model params in this experiment.


6)Pushed all the Code on github by doing Code versioning.
We can do github versioning  at start of project as well.

Performed Data versioning as well through dvc.
